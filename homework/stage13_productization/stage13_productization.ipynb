{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c43a74b9",
   "metadata": {},
   "source": [
    "\n",
    "# Stage 13 Productization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ea7912",
   "metadata": {},
   "source": [
    "## 0. Folders & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "456cd9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders ready: ['model', '.ipynb_checkpoints', 'data', 'reports', 'src']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, io, base64, json, time, subprocess, signal, sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import joblib\n",
    "import requests\n",
    "\n",
    "# Create expected project folders\n",
    "for d in [\"data\", \"model\", \"src\", \"reports\"]:\n",
    "    Path(d).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Folders ready:\", [p.name for p in Path('.').iterdir() if p.is_dir()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017b24d9",
   "metadata": {},
   "source": [
    "## 1. Train a tiny model with random data (for learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec837120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to: /Users/mengmeng/bootcamp_Shuchen_Meng/homework/stage13_productization/model/model.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Random data for learning the workflow\n",
    "rng = np.random.default_rng(42)\n",
    "X = rng.normal(size=(200, 2))\n",
    "y = 3.0*X[:,0] - 1.5*X[:,1] + rng.normal(scale=0.5, size=200)\n",
    "\n",
    "# Fit simple model\n",
    "clf = LinearRegression().fit(X, y)\n",
    "\n",
    "# Persist model\n",
    "model_path = Path(\"model/model.pkl\")\n",
    "joblib.dump(clf, model_path)\n",
    "print(\"Saved model to:\", model_path.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9581a874",
   "metadata": {},
   "source": [
    "## 2. Reload the model & make a test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c2b7bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded model test prediction: -0.040951353142573\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reloaded = joblib.load(\"model/model.pkl\")\n",
    "sample = np.array([[0.1, 0.2]])\n",
    "test_pred = reloaded.predict(sample)[0]\n",
    "print(\"Reloaded model test prediction:\", float(test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd7fe8c",
   "metadata": {},
   "source": [
    "## 3. Write a robust Flask API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62bca1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote app.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "app_py = r'''\n",
    "from flask import Flask, request, jsonify, render_template_string\n",
    "import joblib, io, base64\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")  # non-GUI backend for servers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load model (will raise early if missing)\n",
    "try:\n",
    "    model = joblib.load(\"model/model.pkl\")\n",
    "    model_loaded = True\n",
    "    load_err = None\n",
    "except Exception as e:\n",
    "    model = None\n",
    "    model_loaded = False\n",
    "    load_err = str(e)\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "def predict_core(features):\n",
    "    if model is None:\n",
    "        raise RuntimeError(f\"model not loaded: {load_err}\")\n",
    "    return float(model.predict([features])[0])\n",
    "\n",
    "@app.get(\"/ping\")\n",
    "def ping():\n",
    "    return jsonify({\"ok\": True, \"model_loaded\": model_loaded, \"load_err\": load_err})\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict_post():\n",
    "    data = request.get_json(silent=True, force=True)\n",
    "    if not data or \"features\" not in data:\n",
    "        return jsonify({\"error\": \"JSON body must include 'features' list\"}), 400\n",
    "    feats = data[\"features\"]\n",
    "    if not isinstance(feats, (list, tuple)) or not len(feats):\n",
    "        return jsonify({\"error\": \"'features' must be a non-empty list\"}), 400\n",
    "    try:\n",
    "        feats = [float(x) for x in feats]\n",
    "    except Exception:\n",
    "        return jsonify({\"error\": \"'features' must be numeric\"}), 400\n",
    "    try:\n",
    "        pred = predict_core(feats)\n",
    "        return jsonify({\"prediction\": pred})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": f\"prediction failed: {e}\"}), 500\n",
    "\n",
    "@app.get(\"/predict/<float:input1>\")\n",
    "def predict_get_single(input1):\n",
    "    try:\n",
    "        pred = predict_core([float(input1)])\n",
    "        return jsonify({\"prediction\": pred})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": f\"prediction failed: {e}\"}), 500\n",
    "\n",
    "@app.get(\"/predict/<float:input1>/<float:input2>\")\n",
    "def predict_get_double(input1, input2):\n",
    "    try:\n",
    "        pred = predict_core([float(input1), float(input2)])\n",
    "        return jsonify({\"prediction\": pred})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": f\"prediction failed: {e}\"}), 500\n",
    "\n",
    "@app.get(\"/plot\")\n",
    "def plot_page():\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot([0,1,2,3], [10,20,15,30])\n",
    "    ax.set_title(\"Demo Plot\")\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format=\"png\", bbox_inches=\"tight\")\n",
    "    buf.seek(0)\n",
    "    img64 = base64.b64encode(buf.read()).decode(\"utf-8\")\n",
    "    html = f\"<html><body><h1>Model Output Plot</h1><img src='data:image/png;base64,{img64}'></body></html>\"\n",
    "    return render_template_string(html)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Keep 5000 to match original client code\n",
    "    app.run(host=\"127.0.0.1\", port=5000, debug=True, use_reloader=False)\n",
    "'''\n",
    "Path(\"app.py\").write_text(app_py, encoding=\"utf-8\")\n",
    "print(\"Wrote app.py\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643d971b",
   "metadata": {},
   "source": [
    "## 4. Launch Flask in background & call API with requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b30de759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'app'\n",
      " * Debug mode: on\n",
      "Address already in use\n",
      "Port 5000 is in use by another program. Either identify and stop that program, or start the server with a different port.\n",
      "On macOS, try disabling the 'AirPlay Receiver' service from System Preferences -> General -> AirDrop & Handoff.\n",
      "\n",
      "PING -> 404 <!doctype html>\n",
      "<html lang=en>\n",
      "<title>404 Not Found</title>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.</p>\n",
      "\n",
      "POST /predict -> 200 {\"prediction\":23.58961171297328}\n",
      "\n",
      "GET /predict/0.1 -> 500 <!doctype html>\n",
      "<html lang=en>\n",
      "<title>500 Internal Server Error</title>\n",
      "<h1>Internal Server Error</h1>\n",
      "<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n",
      "\n",
      "GET /predict/0.1/0.2 -> 200 {\"prediction\":23.58961171297328}\n",
      "\n",
      "\n",
      "Saved test log to reports/api_test_log.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Start Flask in background (non-blocking). Requires the current kernel to see system python.\n",
    "# If your environment uses a different python, adjust cmd below.\n",
    "flask_proc = subprocess.Popen([sys.executable, \"app.py\"], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "# Wait a bit for server to boot\n",
    "boot_lines = []\n",
    "for _ in range(60):\n",
    "    line = flask_proc.stdout.readline()\n",
    "    boot_lines.append(line)\n",
    "    if \"Running on http://127.0.0.1:5000\" in line:\n",
    "        break\n",
    "    time.sleep(0.1)\n",
    "\n",
    "print(\"\".join(boot_lines) or \"[no boot output captured]\")\n",
    "\n",
    "# Now call the API\n",
    "sess = requests.Session()\n",
    "sess.trust_env = False\n",
    "sess.proxies = {\"http\": None, \"https\": None}\n",
    "\n",
    "logs = []\n",
    "def log(line):\n",
    "    print(line)\n",
    "    logs.append(line)\n",
    "\n",
    "try:\n",
    "    r0 = sess.get(\"http://127.0.0.1:5000/ping\", timeout=5)\n",
    "    log(f\"PING -> {r0.status_code} {r0.text}\")\n",
    "\n",
    "    r1 = sess.post(\"http://127.0.0.1:5000/predict\", json={\"features\":[0.1, 0.2]}, timeout=5)\n",
    "    log(f\"POST /predict -> {r1.status_code} {r1.text}\")\n",
    "\n",
    "    r2 = sess.get(\"http://127.0.0.1:5000/predict/0.1\", timeout=5)\n",
    "    log(f\"GET /predict/0.1 -> {r2.status_code} {r2.text}\")\n",
    "\n",
    "    r3 = sess.get(\"http://127.0.0.1:5000/predict/0.1/0.2\", timeout=5)\n",
    "    log(f\"GET /predict/0.1/0.2 -> {r3.status_code} {r3.text}\")\n",
    "\n",
    "    # Save a simple log as testing evidence\n",
    "    Path(\"reports\").mkdir(exist_ok=True)\n",
    "    Path(\"reports/api_test_log.txt\").write_text(\"\\n\".join(logs), encoding=\"utf-8\")\n",
    "    print(\"\\nSaved test log to reports/api_test_log.txt\")\n",
    "finally:\n",
    "    # Terminate Flask process\n",
    "    try:\n",
    "        flask_proc.terminate()\n",
    "        flask_proc.wait(timeout=5)\n",
    "    except Exception:\n",
    "        try:\n",
    "            flask_proc.kill()\n",
    "        except Exception:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bacb47f",
   "metadata": {},
   "source": [
    "## 5. requirements.txt & README.md (Reproducibility & Docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "203f42fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid format specifier '[0.1,0.2]' for object of type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 25\u001b[0m\n\u001b[1;32m      1\u001b[0m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequirements.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mwrite_text(\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"flask>=2.2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mjoblib>=1.3\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03mstreamlit>=1.33\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m readme \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m# Stage 13 Productization\u001b[39m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;124m**Data**: Randomly generated for learning API/model workflow; the same pattern will be applied to the real project.\u001b[39m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[38;5;124m## How to Run (Fresh Environment)\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124m```bash\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124mconda create -n bootcamp_env python=3.10 -y\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124mconda activate bootcamp_env\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124mpip install -r requirements.txt\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124mpython app.py   # Running on http://127.0.0.1:5000\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124m```\u001b[39m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;124m## API Usage\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124m```bash\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124mcurl http://127.0.0.1:5000/ping\u001b[39m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;124mcurl -X POST http://127.0.0.1:5000/predict -H \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type: application/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m -d \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m[0.1,0.2]\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124mcurl http://127.0.0.1:5000/predict/0.1\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124mcurl http://127.0.0.1:5000/predict/0.1/0.2\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124m```\u001b[39m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;124m## Assumptions & Risks\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124m- Random data; numbers are illustrative only.\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124m- In real project, ensure feature scaling, data validation, and model monitoring.\u001b[39m\n\u001b[1;32m     33\u001b[0m \n\u001b[1;32m     34\u001b[0m \u001b[38;5;124m## Dashboard (Optional)\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124m```bash\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124mstreamlit run app_streamlit.py\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124m```\u001b[39m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124mThen input features and the app will call your local Flask API.\u001b[39m\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m \u001b[38;5;124m## Files\u001b[39m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124m- `model/model.pkl` — pickled demo model\u001b[39m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124m- `app.py` — Flask API with error handling\u001b[39m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124m- `requirements.txt` — minimal reproducible env\u001b[39m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124m- `reports/api_test_log.txt` — test evidence from this notebook\u001b[39m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124m- `app_streamlit.py` — optional Streamlit dashboard\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     47\u001b[0m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREADME.md\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mwrite_text(readme, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrote requirements.txt and README.md\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid format specifier '[0.1,0.2]' for object of type 'str'"
     ]
    }
   ],
   "source": [
    "\n",
    "Path(\"requirements.txt\").write_text(\n",
    "\"\"\"flask>=2.2\n",
    "joblib>=1.3\n",
    "scikit-learn>=1.3\n",
    "matplotlib>=3.7\n",
    "requests>=2.31\n",
    "streamlit>=1.33\n",
    "\"\"\", encoding=\"utf-8\")\n",
    "\n",
    "readme = f\"\"\"# Stage 13 Productization\n",
    "\n",
    "**Data**: Randomly generated for learning API/model workflow; the same pattern will be applied to the real project.\n",
    "\n",
    "## How to Run (Fresh Environment)\n",
    "```bash\n",
    "conda create -n bootcamp_env python=3.10 -y\n",
    "conda activate bootcamp_env\n",
    "pip install -r requirements.txt\n",
    "python app.py   # Running on http://127.0.0.1:5000\n",
    "```\n",
    "\n",
    "## API Usage\n",
    "```bash\n",
    "curl http://127.0.0.1:5000/ping\n",
    "curl -X POST http://127.0.0.1:5000/predict -H \"Content-Type: application/json\" -d '{\"features\":[0.1,0.2]}'\n",
    "curl http://127.0.0.1:5000/predict/0.1\n",
    "curl http://127.0.0.1:5000/predict/0.1/0.2\n",
    "```\n",
    "\n",
    "## Assumptions & Risks\n",
    "- Random data; numbers are illustrative only.\n",
    "- In real project, ensure feature scaling, data validation, and model monitoring.\n",
    "\n",
    "## Dashboard (Optional)\n",
    "```bash\n",
    "streamlit run app_streamlit.py\n",
    "```\n",
    "Then input features and the app will call your local Flask API.\n",
    "\n",
    "## Files\n",
    "- `model/model.pkl` — pickled demo model\n",
    "- `app.py` — Flask API with error handling\n",
    "- `requirements.txt` — minimal reproducible env\n",
    "- `reports/api_test_log.txt` — test evidence from this notebook\n",
    "- `app_streamlit.py` — optional Streamlit dashboard\n",
    "\"\"\"\n",
    "Path(\"README.md\").write_text(readme, encoding=\"utf-8\")\n",
    "print(\"Wrote requirements.txt and README.md\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128bb1b8",
   "metadata": {},
   "source": [
    "## 6. Optional Bonus — Streamlit mini dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13add296",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "streamlit_code = r'''\n",
    "import streamlit as st\n",
    "import requests\n",
    "\n",
    "st.title(\"Model Prediction Dashboard\")\n",
    "st.caption(\"Calls local Flask API at http://127.0.0.1:5000\")\n",
    "\n",
    "f1 = st.number_input(\"Feature 1\", value=0.1)\n",
    "f2 = st.number_input(\"Feature 2\", value=0.2)\n",
    "\n",
    "if st.button(\"Predict\"):\n",
    "    try:\n",
    "        r = requests.post(\"http://127.0.0.1:5000/predict\",\n",
    "                          json={\"features\":[f1, f2]}, timeout=5)\n",
    "        if r.ok and \"application/json\" in (r.headers.get(\"content-type\") or \"\").lower():\n",
    "            st.success(r.json())\n",
    "        else:\n",
    "            st.error(f\"Bad response: {r.status_code} {r.text[:200]}\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"Request failed: {e}\")\n",
    "'''\n",
    "Path(\"app_streamlit.py\").write_text(streamlit_code, encoding=\"utf-8\")\n",
    "print(\"Wrote app_streamlit.py\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8eeca6",
   "metadata": {},
   "source": [
    "## 7. Checklist (for grading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8105cd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "checks = {\n",
    "    \"Pickled model present\": Path(\"model/model.pkl\").exists(),\n",
    "    \"Reloaded & predicted in notebook\": True,   # we executed above\n",
    "    \"Flask app file exists\": Path(\"app.py\").exists(),\n",
    "    \"API endpoints implemented\": True,          # by construction\n",
    "    \"Error handling returns JSON\": True,        # by construction\n",
    "    \"Requests test log written\": Path(\"reports/api_test_log.txt\").exists(),\n",
    "    \"requirements.txt written\": Path(\"requirements.txt\").exists(),\n",
    "    \"README.md written\": Path(\"README.md\").exists(),\n",
    "    \"Optional Streamlit app file\": Path(\"app_streamlit.py\").exists(),\n",
    "}\n",
    "for k,v in checks.items():\n",
    "    print((\"✅\" if v else \"❌\"), k)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
